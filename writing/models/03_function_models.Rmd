
---
title: "Models 3 - Herbivore function gradients"
output:
  html_document:
    df_print: paged
    fig_width: 7
    fig_height: 6
    fig_caption: true
    css: style.css
    theme: sandstone
  html_notebook: default
  pdf_document: default
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')  ## Hold figure positions
```

#### Cropping - turf removal by small grazers

```{r, include = T, message=F, echo=F}
library(tidyverse); library(funk); library(gridExtra); library(here); library(rethinking)
options(scipen=999)
# setwd(here('grazing-gradients/writing/models'))

## bite predictions for each species
grazer.bites<-read.csv('../../results/functions/grazer_bites_predicted.csv')

# UVC data load
load("../../data/wio_herb_benthic_merged.Rdata")
grazers<-pred %>% filter(FG == 'Herbivore Grazer')
## add genera column
grazers$genus<-str_split_fixed(grazers$species, pattern = '\\ ', n=2)[,1]

## match bite rate for each species. 
grazers$bite.rate<-grazer.bites$median[match(grazers$species, grazer.bites$class)]
## if species is missing, use genera
grazers$bite.rate[is.na(grazers$bite.rate)]<-
          grazer.bites$median[match(grazers$genus[is.na(grazers$bite.rate)], grazer.bites$class)]
## if genera is missing, use global mean
grazers$bite.rate[is.na(grazers$bite.rate)]<-grazer.bites$median[grazer.bites$preds == 'global.mean']

## how many global means in analysis?
t<-data.frame(table(grazers$bite.rate))
grazer.bites$freq<-t$Freq[match(grazer.bites$median, t$Var1)]
g1<-ggplot(grazer.bites, aes(class, freq)) + 
        geom_bar(stat='identity', fill = 'DarkGreen') + coord_flip() +
        labs(x = 'Prediction level', y = 'Total abundance in UVC dataset') + 
        geom_text(aes(class, freq, label = paste(round(median,2), 'bites/min')), size=2, hjust=0) +
        scale_x_discrete(limits = rev(levels(grazer.bites$class))) + lims(y=c(0, 12000))

## how much biomass is global mean in analysis?
t<-aggregate(biomass.kgha ~ bite.rate, grazers, sum)
grazer.bites$freq<-t$biomass.kgha[match(grazer.bites$median, t$bite.rate)]
g2<-ggplot(grazer.bites, aes(class, freq)) + 
        geom_bar(stat='identity', fill = 'DarkGreen') + coord_flip() +
        labs(x = 'Prediction level', y = 'Total biomass in UVC dataset (kg/ha)') + 
        geom_text(aes(class, freq, label = paste(round(median,2), 'bites/min')), size=2, hjust=0) +
        scale_x_discrete(limits = rev(levels(grazer.bites$class))) + lims(y=c(0, 30000))

## what proportion biomass is global means?
#prop.global<-
  t$biomass.kgha[t$bite.rate == grazer.bites$median[grazer.bites$class == 'global.mean']]/sum(t$biomass.kgha)*100
  ## 12.6%
#prop.genera<-
  sum(t$biomass.kgha[t$bite.rate %in% grazer.bites$median[grazer.bites$preds == 'Genus']])/sum(t$biomass.kgha)*100
 ## 54.4%
  
sum(t$biomass.kgha[t$bite.rate %in% grazer.bites$median[grazer.bites$preds == 'Species']])/sum(t$biomass.kgha)*100
## 32.94%
```

After matching UVC species to feeding observations, we get an idea of how much abundance and biomass we can confidently assign to species and genera level bite rate estimates. Global means (i.e. no species or genera information) were required for 20 species, which together comprised 20% of biomass in the dataset. These species were in the genera Plectroglyphidodon, Pomacentrus, Stegastes, Centropyge, Dischistodus, and Chrysiptera.

```{r, include =T, echo= F, messages=F, warning=F,fig.cap='Figure 1: Bite rates assigned to cropping species', fig.height=6, fig.width=6, fig.align='center'}
theme_set(theme_sleek())
grid.arrange(g1, g2, top = 'Prediction levels used for cropper species')
```

UVC biomass estimates were converted to kg carbon of algal material removed per day using 1) species bite rate; 2) individual mass; 3) expected algal consumption rate. Methods are outlined in [methods-summarise.Rmd](../methods-summarise.Rmd) and [02_bite-rate-models.Rmd](../models/02_bite-rate-models.Rmd).

GBR reefs have exceptional grazing rates  at 2000-6000 kg C day^-1^, while other regions have lower and more consistent grazing <1000 kg C day^-1^. 

```{r, include=T, echo=F}

## now convert bite rate to algal consumption based on biomass
grazers$g.carbon.day<-0.0342 * grazers$mass.g^0.816
## now convert bite rate to total bites per day
grazers$daily.bites<-grazers$bite.rate*60*12
## divide by daily bite rate to get grams carbon per bite 
grazers$carbon.per.bite<-grazers$g.carbon.day/(grazers$daily.bites)
## scale up to estimate grams consumed per minute
grazers$cropping<-grazers$carbon.per.bite * grazers$bite.rate

# estimate mean total cropping function per site
h <- grazers %>% 
  ## sum cropping in each transect
        group_by(dataset, date, reef, site, management, transect, 
                 unique.id, depth, FG, transect.area,
                         hard.coral, macroalgae, rubble, substrate, complexity, fish.biom) %>%
          summarise(cropping = sum(cropping), biom=sum(biomass.kgha)) %>%
  ## mean cropping across transects at each site
          group_by(dataset, date, reef, site, management, unique.id, depth, FG, transect.area,
                         hard.coral, macroalgae,  rubble, substrate, complexity, fish.biom) %>%
          summarise(cropping.gram.ha = mean(cropping), biom=mean(biom)) 

## correct cropping to per hectare
## for surveys = 100m2, which is when abundance.500m2 = 5
h$cropping.gram.ha[which(h$transect.area == 100)] <- h$cropping.gram.ha[which(h$transect.area == 100)]/0.01 
## for surveys = 250m2, which is when abundance.500m2 = 2
h$cropping.gram.ha[which(h$transect.area == 250)] <- h$cropping.gram.ha[which(h$transect.area == 250)]/0.025 
## for surveys = 153.9m2, which is when abundance.500m2 = 3.24806 (Seychelles)
h$cropping.gram.ha[is.na(h$transect.area)] <- h$cropping.gram.ha[is.na(h$transect.area)]/0.01539 

## sum within unique.id to account for different transect areas in Maldives
h <- h %>% group_by(dataset, date, reef, site, management, unique.id, depth, FG,
                         hard.coral, macroalgae,  rubble, substrate, complexity, fish.biom) %>%
          summarise(cropping.gram.ha = sum(cropping.gram.ha), biom=sum(biom)) 

save(h, file = '../../results/models/cropper_function.Rdata')

g3<-ggplot(h, aes(reorder(reef, cropping.gram.ha, FUN=median), cropping.gram.ha, fill=dataset)) + geom_boxplot() + xlab('Reef') + ylab('algae removed (grams/ha/minute)') 

g4<-ggplot(h, aes( log10(biom),log10(cropping.gram.ha), col=dataset)) +geom_point() + xlab('Biomass (log10 kg/ha)') + ylab('log10 algae removed (grams/ha/minute)') 

g5<-ggplot(h, aes(biom,cropping.gram.ha, col=dataset)) +geom_point() + xlab('Biomass (kg/ha)') + ylab('algae removed (grams/ha/minute)') 

range(h$cropping.gram.ha)
```

```{r, include =T, echo= F, messages=F, warning=F,fig.cap='Figure 2: Variation in cropping function among reefs', fig.height=6, fig.width=6, fig.align='center'}
g3 + coord_flip()
```

As for decoupling, cropping function is strongly predicted by biomass. Is this because species turnover due to fishing and benthos is minimal? Or because species-specific differences in cropping rate are minimal? Or because we cannot accurately measure algal consumption, so we are simply converting biomass by a constant multiplier?

```{r, include =T, echo= F, messages=F, warning=F,fig.cap='Figure 3: relationship between cropping function and cropper biomass', fig.height=6, fig.width=6, fig.align='center'}
grid.arrange(g4, g5)
```

What about grazers where we have good feeding information? Global means are assigned to >50% of individuals, and 1/3 of UVC biomass. We can drop the global mean estimates to assess whether grazing function *would* decouple from biomass, when species information is resolved.

```{r, include=T, echo=F, fig.cap='Figure ??: biomass and function relationship for grazers with bite rate data', fig.height=6, fig.width=6, fig.align='center'}

grazers$class<-grazer.bites$class[match(grazers$bite.rate,grazer.bites$median)]

# estimate mean total cropping function per site
h <- grazers %>% 
  ## filter for bite rate data
  filter(class != 'global.mean') %>%
  ## sum cropping in each transect
        group_by(dataset, date, reef, site, management, transect, 
                 unique.id, depth, FG, transect.area,
                         hard.coral, macroalgae, rubble, substrate, complexity, fish.biom) %>%
          summarise(cropping = sum(cropping), biom=sum(biomass.kgha)) %>%
  ## mean cropping across transects at each site
          group_by(dataset, date, reef, site, management, unique.id, depth, FG, transect.area,
                         hard.coral, macroalgae,  rubble, substrate, complexity, fish.biom) %>%
          summarise(cropping.gram.ha = mean(cropping), biom=mean(biom)) 

## correct cropping to per hectare
## for surveys = 100m2, which is when abundance.500m2 = 5
h$cropping.gram.ha[which(h$transect.area == 100)] <- h$cropping.gram.ha[which(h$transect.area == 100)]/0.01 
## for surveys = 250m2, which is when abundance.500m2 = 2
h$cropping.gram.ha[which(h$transect.area == 250)] <- h$cropping.gram.ha[which(h$transect.area == 250)]/0.025 
## for surveys = 153.9m2, which is when abundance.500m2 = 3.24806 (Seychelles)
h$cropping.gram.ha[is.na(h$transect.area)] <- h$cropping.gram.ha[is.na(h$transect.area)]/0.01539 

## sum within unique.id to account for different transect areas in Maldives
h <- h %>% group_by(dataset, date, reef, site, management, unique.id, depth, FG,
                         hard.coral, macroalgae,  rubble, substrate, complexity, fish.biom) %>%
          summarise(cropping.gram.ha = sum(cropping.gram.ha), biom=sum(biom)) 

save(h, file = '../../results/models/cropper_function_subset.Rdata')

g4<-ggplot(h, aes( log10(biom),log10(cropping.gram.ha), col=dataset)) +geom_point() + xlab('Biomass (log10 kg/ha)') + ylab('log10 algae removed (grams/ha/minute)') 

g5<-ggplot(h, aes(biom,cropping.gram.ha, col=dataset)) +geom_point() + xlab('Biomass (kg/ha)') + ylab('algae removed (grams/ha/minute)') 

grid.arrange(g4, g5, nrow=2)
```

```{r, include=F}
pairs2(data.frame(h$hard.coral, h$macroalgae, h$rubble, h$substrate, h$complexity, h$management, h$fish.biom, h$cropping.gram.ha), lower.panel=panel.smooth2, upper.panel = panel.cor)
```


#### Browsing - macroalgal removal

Browser bite rates were derived from 2 species in 2 genera. As such, most UVC species were assigned global mean bite rate estimates (Figure 4). However, by biomass, species in the Naso genus accounted for the majority of bite rates, and were assigned genera-level bite rate estimates. ```r, prop.global```% of biomass was assigned global bite rates.

```{r, include = T, message=F, echo=F}
library(tidyverse); library(funk); library(gridExtra); library(here)
options(scipen=999)
# setwd(here('grazing-gradients/writing/models'))

## bite predictions for each species
browser.bites<-read.csv('../../results/functions/browser_bites_predicted.csv')

# UVC data load
load("../../data/wio_herb_benthic_merged.Rdata")
browsers<-pred %>% filter(FG == 'Herbivore Browser')
## add genera column
browsers$genus<-str_split_fixed(browsers$species, pattern = '\\ ', n=2)[,1]

## match bite rate for each species. 
browsers$bite.rate<-browser.bites$median[match(browsers$species, browser.bites$class)]
## if species is missing, use genera
browsers$bite.rate[is.na(browsers$bite.rate)]<-
          browser.bites$median[match(browsers$genus[is.na(browsers$bite.rate)], browser.bites$class)]
## if genera is missing, use global mean
browsers$bite.rate[is.na(browsers$bite.rate)]<-browser.bites$median[browser.bites$preds == 'global.mean']

## how many global means in analysis?
t<-data.frame(table(browsers$bite.rate))
browser.bites$freq<-t$Freq[match(browser.bites$median, t$Var1)]
g1<-ggplot(browser.bites, aes(class, freq)) + 
        geom_bar(stat='identity', fill = 'DarkGreen') + coord_flip() +
        labs(x = 'Prediction level', y = 'Total abundance in UVC dataset') + 
        geom_text(aes(class, freq, label = paste(round(median,2), 'bites/min')), size=2, hjust=0) +
        scale_x_discrete(limits = rev(levels(browser.bites$class))) + lims(y=c(0, 3000))

## how much biomass is global mean in analysis?
t<-aggregate(biomass.kgha ~ bite.rate, browsers, sum)
browser.bites$freq<-t$biomass.kgha[match(browser.bites$median, t$bite.rate)]
g2<-ggplot(browser.bites, aes(class, freq)) + 
        geom_bar(stat='identity', fill = 'DarkGreen') + coord_flip() +
        labs(x = 'Prediction level', y = 'Total biomass in UVC dataset (kg/ha)') + 
        geom_text(aes(class, freq, label = paste(round(median,2), 'bites/min')), size=2, hjust=0) +
        scale_x_discrete(limits = rev(levels(browser.bites$class))) + lims(y=c(0, 40000))

## what proportion biomass is global means?
#prop.global<-
  t$biomass.kgha[t$bite.rate == browser.bites$median[browser.bites$class == 'global.mean']]/sum(t$biomass.kgha)*100
  ## 46.9%
#prop.genera<-
  sum(t$biomass.kgha[t$bite.rate %in% browser.bites$median[browser.bites$preds == 'Genus']])/sum(t$biomass.kgha)*100
 ## 53.1%
  
sum(t$biomass.kgha[t$bite.rate %in% browser.bites$median[browser.bites$preds == 'Species']])/sum(t$biomass.kgha)*100
## 0%

```

```{r, include =T, echo= F, messages=F, warning=F,fig.cap='Figure 4: Bite rates assigned to browsing species', fig.height=6, fig.width=6, fig.align='center'}
theme_set(theme_sleek())
grid.arrange(g1, g2, top = 'Prediction levels used for browser species')
```

UVC biomass estimates were converted to mass standardized bite rates (Bellwood et al. 2006, Bennet & Bellwood 2011, Verges et al. 2012) using 1) species bite rate and 2) individual mass (kg). However, because >90% of dataset biomass is assigned a bite rate ~10 bites/min, this means that mass standardized bite rates just represents 10*biomass. So, biomass and function are (almost) perfectly correlated.

We can't really measure this relationship without more browsing feeding information, particularly on siganids (rabbitfish) and platax (batfish) which are unrepresented as genera. Especially important to get siganid info. as these are high biomass at Seychelles macroalgal sites and not really detected anywhere else - implications for browsing function after bleaching. 


```{r, include=T, echo=F}
## now convert bite rate to mass standardized bite rates
browsers$browsing<-browsers$bite.rate * (browsers$mass.g/1000)

# estimate mean total browsing function per site
h <- browsers %>% 
  ## sum browsing in each transect
        group_by(dataset, date, reef, site, management, transect, 
                 unique.id, depth, FG, transect.area,
                         hard.coral, macroalgae, rubble, substrate, complexity, fish.biom) %>%
          summarise(browsing = sum(browsing), biom=sum(biomass.kgha)) %>%
  ## mean browsing across transects at each site
          group_by(dataset, date, reef, site, management, unique.id, depth, FG, transect.area,
                         hard.coral, macroalgae,  rubble, substrate, complexity, fish.biom) %>%
          summarise(browsing = mean(browsing), biom=mean(biom)) 

## correct browsing to per hectare
## for surveys = 100m2, which is when abundance.500m2 = 5
h$browsing[which(h$transect.area == 100)] <- h$browsing[which(h$transect.area == 100)]/0.01 
## for surveys = 250m2, which is when abundance.500m2 = 2
h$browsing[which(h$transect.area == 250)] <- h$browsing[which(h$transect.area == 250)]/0.025 
## for surveys = 153.9m2, which is when abundance.500m2 = 3.24806 (Seychelles)
h$browsing[is.na(h$transect.area)] <- h$browsing[is.na(h$transect.area)]/0.01539 

## sum within unique.id to account for different transect areas in Maldives
h <- h %>% group_by(dataset, date, reef, site, management, unique.id, depth, FG,
                         hard.coral, macroalgae,  rubble, substrate, complexity, fish.biom) %>%
          summarise(browsing = sum(browsing), biom=sum(biom)) 

save(h, file = '../../results/models/browser_function.Rdata')

g3<-ggplot(h, aes(reorder(reef, browsing, FUN=median), browsing, fill=dataset)) + geom_boxplot() + xlab('Reef') + ylab('mass-standardized bite rates (bites * kg per minute per ha)') 

g4<-ggplot(h, aes( log10(biom),log10(browsing), col=dataset)) +geom_point() + xlab('Biomass (log10 kg/ha)') + ylab('log10 bites * kg per minute') 

g5<-ggplot(h, aes(biom, browsing, col=dataset)) +geom_point() + xlab('Biomass (kg/ha)') + ylab('mass-standardized bites (bites * kg per minute per ha)') + xlim(c(0,500)) + ylim(c(0, 5000))

range(h$browsing)
```

```{r, include =T, echo= F, messages=F, warning=F,fig.cap='Figure 5: Variation in browsing function among reefs', fig.height=6, fig.width=6, fig.align='center'}
g3 + coord_flip()
```

```{r, include =T, echo= F, messages=F, warning=F,fig.cap='Figure 6: relationship between browsing function and browser biomass', fig.height=6, fig.width=6, fig.align='center'}
grid.arrange(g4, g5)
```

#### Scraping functions = potential area grazed

For scrapers, we are combining bite frequencies with bite areas. Datasets are independent, and separate size models are fitted to each.

```{r, include = T, message=F, echo=F}
# UVC data load
load("../../data/wio_herb_benthic_merged.Rdata")
scrapers.uvc<-pred %>% filter(FG == 'Herbivore Scraper')
scrapers.uvc$species<-as.factor(scrapers.uvc$sp)
## add genera column
scrapers.uvc$genus<-str_split_fixed(scrapers.uvc$species, pattern = '\\ ', n=2)[,1]
scrapers.uvc$genus<-as.factor(scrapers.uvc$genus)


## predictive model load
load(file = '../../results/models/bites_scrapers.Rdata')

## bite predictions for each species
d.pred <-data.frame(sp = scrapers.uvc$species, Genus = scrapers.uvc$genus, TL=scrapers.uvc$length.cm, dataset='NA')
## subset for species in bite rate obs
d.pred <- d.pred[d.pred$sp %in% scrapers$sp,]; d.pred<-droplevels(d.pred)
a.dataset.zero = matrix(0, 1000, 3)
link.obs.sp<-link(scrape.m, n = 1000, data = as.list(d.pred), replace=list(X3 = a.dataset.zero))
scrapers.uvc$biterate[scrapers.uvc$sp %in% scrapers$sp]<-apply(link.obs.sp, 2, median)

## uncertainty
pred.PI<-apply(link.obs.sp, 2, PI, prob = 0.95)
scrapers.uvc$upper[scrapers.uvc$sp %in% scrapers$sp]<-pred.PI[2,]
scrapers.uvc$lower[scrapers.uvc$sp %in% scrapers$sp]<-pred.PI[1,]

## how much biomass and abunance, and how many species, require genus level predictions?
sum(scrapers.uvc$biomass.kgha[is.na(scrapers.uvc$biterate)])/sum(scrapers.uvc$biomass.kgha)*100 ### 19%
sum(scrapers.uvc$abundance.500m2[is.na(scrapers.uvc$biterate)])/sum(scrapers.uvc$abundance.500m2)*100 ### 21%

## assign genus for missing species
scraper.bites<-read.csv(file = '../../results/functions/scraper_bites_predicted.csv')
scrapers.uvc$biterate[is.na(scrapers.uvc$biterate)]<-scraper.bites$median[match(scrapers.uvc$genus[is.na(scrapers.uvc$biterate)], scraper.bites$class)]
  

## area predictions for body size
load(file = '../../results/models/area_scrapers.Rdata')
d.pred <-data.frame(TL=scrapers.uvc$length.cm)
link.obs.sp<-link(scrape.m2, n = 1000, data = as.list(d.pred))
scrapers.uvc$bitearea<-data.frame(median = apply(link.obs.sp, 2, median))
pred.PI<-apply(link.obs.sp, 2, PI, prob = 0.95)
scrapers.uvc$upperarea<-pred.PI[2,]
scrapers.uvc$lowerarea<-pred.PI[1,]



## what proportion biomass is global means?
newsp<-unique(scrapers.uvc$species)[!unique(scrapers.uvc$species) %in% scraper.bites$class] ## new species

## how much biomass is global mean in analysis?
t<- scrapers.uvc 
t$id <- ifelse(t$species %in% newsp, 'Genera', 'Species')
tot<-sum(scrapers.uvc$biomass.kgha)
t %>% group_by(id) %>% summarise(b = sum(biomass.kgha)/tot*100)


```

Scraper function = area scraped * bite rate, where area scraped is predicted by individual body size and bite rate is predicted by individual body size, species and genus. For units, we have area scraped in mm^2^, bite rate in bites per minute, and biomass in kg per hectare. After converting to area scraped per minute per hectare, millimetre areas are obviously very large for a per hectare biomass estimate. Converting mm^2^ to m^2^ requires dividing by 1,000,000.


```{r, include=T, echo=F}
## now convert bite rate to area scraped
scrapers.uvc$scraping<-scrapers.uvc$biterate * scrapers.uvc$bitearea / 1000000

# estimate mean total scraping function per site
h <- scrapers.uvc %>% 
  ## sum scraping in each transect
        group_by(dataset, date, reef, site, management, transect, 
                 unique.id, depth, FG, transect.area,
                         hard.coral, macroalgae, rubble, substrate, complexity, fish.biom) %>%
          summarise(scraping = sum(scraping), biom=sum(biomass.kgha)) %>%
  ## mean scraping across transects at each site
          group_by(dataset, date, reef, site, management, unique.id, depth, FG, transect.area,
                         hard.coral, macroalgae,  rubble, substrate, complexity, fish.biom) %>%
          summarise(scraping = mean(scraping), biom=mean(biom)) 

## correct scraping to per hectare
## for surveys = 100m2, which is when abundance.500m2 = 5
h$scraping[which(h$transect.area == 100)] <- h$scraping[which(h$transect.area == 100)]/0.01 
## for surveys = 250m2, which is when abundance.500m2 = 2
h$scraping[which(h$transect.area == 250)] <- h$scraping[which(h$transect.area == 250)]/0.025 
## for surveys = 153.9m2, which is when abundance.500m2 = 3.24806 (Seychelles)
h$scraping[is.na(h$transect.area)] <- h$scraping[is.na(h$transect.area)]/0.01539 

## sum within unique.id to account for different transect areas in Maldives
h <- h %>% group_by(dataset, date, reef, site, management, unique.id, depth, FG,
                         hard.coral, macroalgae,  rubble, substrate, complexity, fish.biom) %>%
          summarise(scraping = sum(scraping), biom=sum(biom)) 

save(h, file = '../../results/models/scraper_function.Rdata')

g3<-ggplot(h, aes(reorder(reef, scraping, FUN=median), scraping, fill=dataset)) + geom_boxplot() + xlab('Reef') + ylab('area scraped (m2) per minute per ha') 

g4<-ggplot(h, aes( biom,scraping, col=dataset)) +geom_point() + scale_x_log10() + scale_y_log10() + xlab('Biomass kg/ha)') + ylab('area scraped (m2) per minute per ha') 

g5<-ggplot(h, aes(biom, scraping, col=dataset)) +geom_point() + xlab('Biomass (kg/ha)') + ylab('area scraped (m2) per minute per ha)') #+ xlim(c(0,500)) + ylim(c(0, 5000))
```

```{r, include =T, echo= F, messages=F, warning=F,fig.cap='Figure 5: Variation in scraping function among reefs', fig.height=6, fig.width=6, fig.align='center'}
g3 + coord_flip()
```

```{r, include =T, echo= F, messages=F, warning=F,fig.cap='Figure 6: relationship between scraping function and browser biomass', fig.height=6, fig.width=6, fig.align='center'}
grid.arrange(g4, g5)
```

#### Statistical models

Fitting linear models to raw function ~ biomass data. Departure from linearity allows us to assess degree of decoupling, with outliers (i.e. residuals) and random effects (dataset) allowing us to measure where decoupling might occur. 

```{r, include=T, echo=F, message=F, warning=F,fig.cap='Figure 7: decoupling from residual analysis: cropper and browser', fig.height=5, fig.width=8, fig.align='center'}
load(file = '../../results/models/cropper_function.Rdata')
library(lme4); library(piecewiseSEM)
m.graze<-lmer(cropping.gram.ha ~ biom + (1 | dataset), h)
h$resid<-resid(m.graze)
rsq.g<-rsquared(m.graze)

g1<-ggplot(h, aes(biom, resid, col=dataset)) + 
      geom_point() + 
      guides(col=FALSE) +
      labs(x = 'Biomass kg/ha', y = 'Deviation from grazing function', main='Cropper') +
      annotate(500, 1.8, geom='text', label='More algal removal') +
      annotate(500, -1.2, geom='text', label='Less algal removal') +
      annotate(Inf, -Inf, geom='text', vjust=-2, hjust=1, label=paste('R2 = ', round(rsq.g$Marginal, 2)))

load(file = '../../results/models/browser_function.Rdata')

m.browse<-lmer(browsing ~ biom + (1 | dataset), h)
h$resid<-resid(m.browse)
rsq.b<-rsquared(m.browse)

g2<-ggplot(h, aes(biom, resid, col=dataset)) + 
      geom_point() + 
      guides(col=FALSE) +
      labs(x = 'Biomass kg/ha', y = 'Deviation from grazing function', main='Browser') +
      annotate(1500, 120, geom='text', label='More algal removal') +
      annotate(1500, -200, geom='text', label='Less algal removal') +
      annotate(Inf, -Inf, geom='text', vjust=-2, hjust=2, label=paste('R2 = ', round(rsq.b$Marginal, 2))) 

load(file = '../../results/models/scraper_function.Rdata')

m.scrape<-lmer(scraping ~ biom + (1 | dataset), h)
h$resid<-resid(m.scrape)
rsq.b<-rsquared(m.scrape)

g3<-ggplot(h, aes(biom, resid, col=dataset)) + 
      geom_point() + 
      guides(col=FALSE) +
      labs(x = 'Biomass kg/ha', y = 'Deviation from grazing function', main='Scraper') +
      annotate(1500, 750000, geom='text', label='More algal removal') +
      annotate(1500, -400000, geom='text', label='Less algal removal') +
      annotate(Inf, -Inf, geom='text', vjust=-2, hjust=2, label=paste('R2 = ', round(rsq.b$Marginal, 2))) 


grid.arrange(g1, g2,g3, nrow=1)
```
